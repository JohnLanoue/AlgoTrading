{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d8945c",
   "metadata": {},
   "source": [
    "## Intent 9/6/2025: To create a LSTM vectorized Backtest function that can run with a data frame of predictions.\n",
    "\n",
    "Start with building a LTSM Predictor hence we already have a get data function.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "443153c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0661\n",
      "Epoch 2/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0214\n",
      "Epoch 3/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0123\n",
      "Epoch 4/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0136\n",
      "Epoch 5/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0099\n",
      "Epoch 6/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0117\n",
      "Epoch 7/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0095\n",
      "Epoch 8/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0172\n",
      "Epoch 9/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0079\n",
      "Epoch 10/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0098\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "Actual Values:\n",
      "[151.0, 128.98, 140.78, 147.31, 135.23, 136.35, 147.74, 127.42, 130.08, 136.44, 149.7901, 130.82, 144.49, 150.17, 145.3644, 127.6, 146.96, 132.31, 134.9, 144.33, 133.83, 155.96, 133.3022, 144.42, 137.6304, 147.6, 144.89, 134.85, 128.0, 121.9771, 135.0, 139.5, 125.37, 147.675, 130.82, 130.36, 130.01, 133.2002, 135.37, 152.13, 149.54, 131.6608, 132.36, 139.205, 152.055, 146.71, 156.03, 139.2942, 148.18, 134.69, 128.9101, 151.09, 150.64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/pc8xl1ls1y35f9xzjdj87z0c0000gn/T/ipykernel_25375/2980423974.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  v['Predictions'] = LSTM_predictions\n"
     ]
    }
   ],
   "source": [
    "#Final TEST \n",
    "from Packages.Alpaca_Connection import get_data_today\n",
    "df = df_finalize(get_data_today('mmm'))\n",
    "#I don't think we actually need this. Apendix from other trained data.  \n",
    "#X_train, X_test, y_train, y_test = lstm_prep(df)\n",
    "pred = lstm(df)\n",
    "signal = vecorized_buy_sell(pred, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd40c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "2025-09-13 13:42:55.322590: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0574\n",
      "Epoch 2/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0275\n",
      "Epoch 3/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0148\n",
      "Epoch 4/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0171\n",
      "Epoch 5/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0121\n",
      "Epoch 6/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0112\n",
      "Epoch 7/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0097\n",
      "Epoch 8/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0107\n",
      "Epoch 9/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0094\n",
      "Epoch 10/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0092\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnlanoue/Documents/GitHub/AlgoTrading/Packages/lstm.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  v['Predictions'] = LSTM_predictions\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (38) does not match length of index (53)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3r/pc8xl1ls1y35f9xzjdj87z0c0000gn/T/ipykernel_31100/2348681033.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvecorized_buy_sell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/AlgoTrading/Packages/lstm.py\u001b[0m in \u001b[0;36mvecorized_buy_sell\u001b[0;34m(ls_pred, arr_actuals)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mbuy_sell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Actuals\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr_actuals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, \"Predictions\":LSTM_predictions })\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Predictions\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mls_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Predictions Offset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"signal\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Actuals\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Predictions Offset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4522\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m         \"\"\"\n\u001b[0;32m-> 4524\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m         if (\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5266\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5267\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5268\u001b[0m         if (\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \"\"\"\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (38) does not match length of index (53)"
     ]
    }
   ],
   "source": [
    "from Packages.Alpaca_Connection import get_data_today\n",
    "df = get_data_today('mmm')\n",
    "from Packages.lstm import lstm, lstm_prep, df_finalize, lstm, vecorized_buy_sell\n",
    "df = df_finalize(get_data_today('mmm'))\n",
    "X_train, X_test, y_train, y_test = lstm_prep(df)\n",
    "pred = lstm(df)\n",
    "signal = vecorized_buy_sell(pred, X_test)\n",
    "signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1fcb451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 07:22:51.605555: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#Basic \n",
    "import numpy as np\n",
    "#LSTM Functions\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import LSTM \n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650c3e8",
   "metadata": {},
   "source": [
    "## Seperate: The LSTM Predictions\n",
    "Future Items: \n",
    "    Customize the future_days available.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b361161",
   "metadata": {},
   "source": [
    "Overhead for the data: Consider this an independant function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b633b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_finalize(df ):\n",
    "#   PRE: Recieves a data frame from the Alpaca_connection.get_data_today package.  Pandas is already installed.  \n",
    "#   POST: Finalizes a data frame that is ready for next steps. \n",
    "#   Intent: Band-aid for data handling.  Consider closing the gap in get_data_today\n",
    "#   Improvements: Replace function ALL together\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns = {'open':'Open', 'high':'High', 'low':'Low', 'close':'Close', 'volume':'Volume', 'trade_count':'Trade Count'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8815b1",
   "metadata": {},
   "source": [
    "Below we should encapsulate this into a single function that can prep for LTSM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a55c084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_prep(df, future_days = 38):\n",
    "#.  PRE: Pandas is already installed and we recieve a data frame\n",
    "#.  POST: We have split data frames that is ready for train/testing.  \n",
    "#.  Intent: Take the incoming data frame and break it out to train/test\n",
    "#.  Improvement: Convert the output to df.  \n",
    "\n",
    "#.  THis is the target preictor: Conside\n",
    "    df['Prediction'] = df[['Close']].shift(-future_days)\n",
    "    \n",
    "#.  We identify the predictor/response.  \n",
    "    X = np.array(df.drop(['Prediction','index', 'symbol', 'timestamp'], axis = 1))[:-future_days]\n",
    "    y = np.array(df['Prediction'])[:-future_days]\n",
    "\n",
    "\n",
    "    # Finally, we use the prediction column to create an array of the the future predictor days.  \n",
    "    # Get the last 'x' rows of the feature data set\n",
    "    x_future = df.drop(['index','Prediction', 'symbol', 'timestamp'],axis = 1)[:-future_days]\n",
    "    x_future = x_future.tail(future_days)\n",
    "    x_future = np.array(x_future)\n",
    "    # ## Splitting the data for performance testing\n",
    "    # In addition to the visual analysis, we are going to want to use our conventional Test/train split in order to train the data. We can use our conventional train_test_split dividing our 'live' close date with our prediction close date.   \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88743e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Builds the actual LTSM Network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67d3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(df, future_days = 38):\n",
    "#.   PRE: We recieve a data frame that is fit for LSTM training.  \n",
    "#.   Post: We return our predicted values.  \n",
    "#.   Intent: TO be able to generate the prdeictions from the lSTM \n",
    "#.   Improvements: Return the test results: In case we get a low accuracy.  More parameters for fiddlingwith the layers and hyperparameters.  \n",
    "\n",
    "    # As seen before we are going to look at the market close data and prepare all but 38 values to generate predictions.  \n",
    "    lstmData = df.filter(['Close'])\n",
    "    dataset = lstmData.values\n",
    "    training_data_len = len(dataset)-future_days\n",
    "\n",
    "\n",
    "    # Now as mentioned above, we have to scale the data.  Using the min max scaler we can turn all of our data into decimals (except for the min =0 and max =1).  We will save this data into our scaled_data datset.    \n",
    "    #Scale the data \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "\n",
    "    # Below you will see that we need to split the data again into x and y train and test.  Using a 60 day offset we can append them to an empty list using the prior 60 days to predict the next 60 days.  \n",
    "    #Re create Training Set \n",
    "    lstm_train_data = scaled_data[0:training_data_len,:]\n",
    "    test_data = scaled_data[training_data_len - 60: ,:]\n",
    "\n",
    "    # Create the datasets\n",
    "    lstm_x_train = []\n",
    "    lstm_y_train = []\n",
    "    lstm_x_test = []\n",
    "    lstm_y_test = dataset[training_data_len:, :]\n",
    "\n",
    "    for i in range(60, len(lstm_train_data)):\n",
    "        lstm_x_train.append(lstm_train_data[i-60:i])\n",
    "        lstm_y_train.append(lstm_train_data[i,0])\n",
    "    \n",
    "\n",
    "    for i in range(60, len(test_data)): \n",
    "        lstm_x_test.append(test_data[i-60:i, 0])    \n",
    "\n",
    "\n",
    "    # Now we have to convert the lists into numpy arrays so the data can be read.  Also, we have to reshape them into a format that the LSTM will understand.  \n",
    "\n",
    "    #Conver to numpy\n",
    "    lstm_x_train, lstm_y_train =   np.array(lstm_x_train), np.array(lstm_y_train)\n",
    "    lstm_x_test = np.array(lstm_x_test)\n",
    "    #Reshape the data\n",
    "    lstm_x_train = np.reshape(lstm_x_train, (lstm_x_train.shape[0], lstm_x_train.shape[1], 1))\n",
    "    lstm_x_test = np.reshape(lstm_x_test, (lstm_x_test.shape[0], lstm_x_test.shape[1], 1))\n",
    "\n",
    "\n",
    "    # Finally, we are back to building the models.  We are using 4 layers: The first two training layers then a dense layer and finally an output layer.  \n",
    "    model = Sequential() \n",
    "    model.add(LSTM(50, return_sequences = True, input_shape=(lstm_x_train.shape[1],1)))\n",
    "    model.add(LSTM(50, return_sequences = False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    # Now that we have created the network, we can run the data through using the MSE method.  We will use 10 epocs because the loss is low, but futher iterations are not necessary.  Finally we have to undo the scaling to our predictions.  \n",
    "\n",
    "    #Compile the model \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    #Train the model \n",
    "    model.fit(lstm_x_train, lstm_y_train, batch_size = 1, epochs = 10)  \n",
    "    LSTM_predictions = model.predict(lstm_x_test)\n",
    "    LSTM_predictions = scaler.inverse_transform(LSTM_predictions)\n",
    "    LSTM_predictions\n",
    "\n",
    "\n",
    "    # Because of the necessary transformations that were done to the model, we cannot use the same function as above. However we can poach  a massive chunk from above and paste it into our model.  \n",
    "\n",
    "    t = lstmData[:training_data_len]\n",
    "    v = lstmData[training_data_len:]\n",
    "    v['Predictions'] = LSTM_predictions\n",
    "\n",
    "\n",
    "\n",
    "#    print(mean_squared_error(X_test[:38],LSTM_predictions))\n",
    "#    print(\"Actual Values:\")\n",
    "#    print([row[2] for row in X_test])\n",
    "    return  LSTM_predictions# [row[2] for row in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d534d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we have the actual buy sell strategy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234d846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecorized_buy_sell(ls_pred, arr_actuals):\n",
    "    import pandas as pd\n",
    "    buy_sell = pd.DataFrame({\"Actuals\": [row[2] for row in arr_actuals][:]})#, \"Predictions\":LSTM_predictions })\n",
    "    buy_sell[\"Predictions\"] = ls_pred\n",
    "    buy_sell[\"Predictions Offset\"] = pd.DataFrame(ls_pred).shift(1)\n",
    "    buy_sell[\"signal\"] = np.where(buy_sell[\"Actuals\"]> buy_sell[\"Predictions Offset\"], 1, -1 )\n",
    "    buy_sell[\"returns\"] = np.log(buy_sell[\"Actuals\"]/ buy_sell[\"Actuals\"].shift(1))\n",
    "    buy_sell[\"strategy\"] = buy_sell[\"returns\"]*buy_sell[\"signal\"]\n",
    "    return buy_sell\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23ffd9d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (38) does not match length of index (53)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3r/pc8xl1ls1y35f9xzjdj87z0c0000gn/T/ipykernel_31100/1014000006.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvecorized_buy_sell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#signal = vectorized_backtest(pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3r/pc8xl1ls1y35f9xzjdj87z0c0000gn/T/ipykernel_31100/3748458771.py\u001b[0m in \u001b[0;36mvecorized_buy_sell\u001b[0;34m(ls_pred, arr_actuals)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbuy_sell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Actuals\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr_actuals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, \"Predictions\":LSTM_predictions })\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Predictions\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mls_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Predictions Offset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"signal\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Actuals\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Predictions Offset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4522\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m         \"\"\"\n\u001b[0;32m-> 4524\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m         if (\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5266\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5267\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5268\u001b[0m         if (\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \"\"\"\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (38) does not match length of index (53)"
     ]
    }
   ],
   "source": [
    "signal = vecorized_buy_sell(pred, X_test)\n",
    "#signal = vectorized_backtest(pred)\n",
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "51156ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row[2] for row in X_test][51:]#[len(pred):]\n",
    "len([row[2] for row in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "53037070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_backtest(ls, cycles = 32): \n",
    "#.   Pre: Takes a list of stock market predictions.\n",
    "#.   Post: We use these predictions to buy/sell through the entire cycle. \n",
    "#.   Intent: Basic backtest to view strategy moving forward. \n",
    "#.   FIX THE HARDCODE.  Improvement: Allow for downstream charting. \n",
    "    import pandas as pd\n",
    "    buy_sell = pd.DataFrame({\"Actuals\": [row[2] for row in X_test][53:]})#, \"Predictions\":LSTM_predictions })\n",
    "    buy_sell[\"Predictions\"] = pred\n",
    "    buy_sell[\"Predictions Offset\"] = pd.DataFrame(LSTM_predictions).shift(1)\n",
    "    buy_sell[\"signal\"] = np.where(buy_sell[\"Actuals\"]> buy_sell[\"Predictions Offset\"], 1, -1 )\n",
    "    buy_sell[\"returns\"] = np.log(buy_sell[\"Actuals\"]/ buy_sell[\"Actuals\"].shift(1))\n",
    "    buy_sell[\"strategy\"] = buy_sell[\"returns\"]*buy_sell[\"signal\"]\n",
    "    #buy_sell\n",
    "    \n",
    "    buy_sell[[\"returns\", \"strategy\"]].sum()\n",
    "    buy_sell[[\"returns\", \"strategy\"]].sum().apply(np.exp)\n",
    "    buy_sell[[\"returns\", \"strategy\"]].cumsum().apply(np.exp).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_test[0][2]\n",
    "#df.head()\n",
    "#X_test[0]\n",
    "\n",
    "    \n",
    "[row[2] for row in X_test]\n",
    "\n",
    "\n",
    "# ## Buy/Sell Strategy: \n",
    "# If the next prediction is less than current actual: Sell\n",
    "# If the next prediction is more than the current actual: Buy\n",
    "# Create a dataframe of the values with the buy/sell signal.  \n",
    "# Then create look into backtesting the signal.  \n",
    "\n",
    "\n",
    "def vectorized_backtest(ls, cycles = 32): \n",
    "#.   Pre: Takes a list of stock market predictions.\n",
    "#.   Post: We use these predictions to buy/sell through the entire cycle. \n",
    "#.   Intent: Basic backtest to view strategy moving forward. \n",
    "#.   Improvement: Allow for downstream charting\n",
    "    import pandas as pd\n",
    "    buy_sell = pd.DataFrame({\"Actuals\": [row[2] for row in X_test][15:]})#, \"Predictions\":LSTM_predictions })\n",
    "    buy_sell[\"Predictions\"] = LSTM_predictions\n",
    "    buy_sell[\"Predictions Offset\"] = pd.DataFrame(LSTM_predictions).shift(1)\n",
    "    buy_sell[\"signal\"] = np.where(buy_sell[\"Actuals\"]> buy_sell[\"Predictions Offset\"], 1, -1 )\n",
    "    buy_sell[\"returns\"] = np.log(buy_sell[\"Actuals\"]/ buy_sell[\"Actuals\"].shift(1))\n",
    "    buy_sell[\"strategy\"] = buy_sell[\"returns\"]*buy_sell[\"signal\"]\n",
    "    #buy_sell\n",
    "    \n",
    "    buy_sell[[\"returns\", \"strategy\"]].sum()\n",
    "    buy_sell[[\"returns\", \"strategy\"]].sum().apply(np.exp)\n",
    "    buy_sell[[\"returns\", \"strategy\"]].cumsum().apply(np.exp).plot()\n",
    "\n",
    "\n",
    "# ## Average period return risk statistics for both the stock and strategy. \n",
    "# (32 = # of cycles; 252 = annual period)\n",
    "# \n",
    "# Calculates the period mean return in both log and regular price\n",
    "#  \n",
    "# Conclusion(8/30): Equal risk, much higher reward\n",
    "    buy_sell[['returns', 'strategy']].mean()*cycles\n",
    "    np.exp(buy_sell[['returns', 'strategy']].mean()*cycles)-1\n",
    "buy_sell[['returns', 'strategy']].std()*cycles**.5\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "(buy_sell[['returns', 'strategy']].apply(np.exp)-1).std()*32**.5\n",
    "\n",
    "\n",
    "# ## Evaluate the drawdaown with the cummax/cumret\n",
    "# \n",
    "# Defines a new column, cumret, with a gross performance over time\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "## Evaluate the drawdaown with the cummax/cumret \n",
    "buy_sell['cumret'] =buy_sell['strategy'].cumsum().apply(np.exp)\n",
    "\n",
    "\n",
    "# Defines yet another column with a running maximum value of the gross performance\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "buy_sell['cummax'] = buy_sell['cumret'].cummax()\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "buy_sell[['cumret', 'cummax']].dropna().plot(figsize= (10,6))\n",
    "\n",
    "\n",
    "# The max drawdown is calcualated as the difference between the two columns\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "drawdown = buy_sell['cummax'] - buy_sell['cumret']\n",
    "drawdown.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d4a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PRE: Accepts a pandas data frame with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b0af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
