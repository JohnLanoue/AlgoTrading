{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d8945c",
   "metadata": {},
   "source": [
    "## Intent 9/6/2025: To create a LSTM vectorized Backtest function that can run with a data frame of predictions.\n",
    "\n",
    "Start with building a LTSM Predictor hence we already have a get data function.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dfe6e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0661\n",
      "Epoch 2/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0214\n",
      "Epoch 3/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0123\n",
      "Epoch 4/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0136\n",
      "Epoch 5/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0099\n",
      "Epoch 6/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0117\n",
      "Epoch 7/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0095\n",
      "Epoch 8/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0172\n",
      "Epoch 9/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0079\n",
      "Epoch 10/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0098\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "Actual Values:\n",
      "[151.0, 128.98, 140.78, 147.31, 135.23, 136.35, 147.74, 127.42, 130.08, 136.44, 149.7901, 130.82, 144.49, 150.17, 145.3644, 127.6, 146.96, 132.31, 134.9, 144.33, 133.83, 155.96, 133.3022, 144.42, 137.6304, 147.6, 144.89, 134.85, 128.0, 121.9771, 135.0, 139.5, 125.37, 147.675, 130.82, 130.36, 130.01, 133.2002, 135.37, 152.13, 149.54, 131.6608, 132.36, 139.205, 152.055, 146.71, 156.03, 139.2942, 148.18, 134.69, 128.9101, 151.09, 150.64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/pc8xl1ls1y35f9xzjdj87z0c0000gn/T/ipykernel_25375/2980423974.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  v['Predictions'] = LSTM_predictions\n"
     ]
    }
   ],
   "source": [
    "#Final TEST \n",
    "from Packages.Alpaca_Connection import get_data_today\n",
    "df = df_finalize(get_data_today('mmm'))\n",
    "#I don't think we actually need this. Apendix from other trained data.  \n",
    "#X_train, X_test, y_train, y_test = lstm_prep(df)\n",
    "pred = lstm(df)\n",
    "signal = vecorized_buy_sell(pred, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e649dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "2025-09-13 13:42:55.322590: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0574\n",
      "Epoch 2/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0275\n",
      "Epoch 3/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0148\n",
      "Epoch 4/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0171\n",
      "Epoch 5/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0121\n",
      "Epoch 6/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0112\n",
      "Epoch 7/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0097\n",
      "Epoch 8/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0107\n",
      "Epoch 9/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0094\n",
      "Epoch 10/10\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0092\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnlanoue/Documents/GitHub/AlgoTrading/Packages/lstm.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  v['Predictions'] = LSTM_predictions\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (38) does not match length of index (53)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3r/pc8xl1ls1y35f9xzjdj87z0c0000gn/T/ipykernel_31100/2348681033.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvecorized_buy_sell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/AlgoTrading/Packages/lstm.py\u001b[0m in \u001b[0;36mvecorized_buy_sell\u001b[0;34m(ls_pred, arr_actuals)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mbuy_sell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Actuals\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr_actuals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, \"Predictions\":LSTM_predictions })\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Predictions\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mls_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Predictions Offset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"signal\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Actuals\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mbuy_sell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Predictions Offset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4522\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m         \"\"\"\n\u001b[0;32m-> 4524\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m         if (\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5266\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5267\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5268\u001b[0m         if (\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \"\"\"\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (38) does not match length of index (53)"
     ]
    }
   ],
   "source": [
    "from Packages.Alpaca_Connection import get_data_today\n",
    "df = get_data_today('mmm')\n",
    "from Packages.lstm import lstm, lstm_prep, df_finalize, lstm, vecorized_buy_sell\n",
    "df = df_finalize(get_data_today('mmm'))\n",
    "X_train, X_test, y_train, y_test = lstm_prep(df)\n",
    "pred = lstm(df)\n",
    "signal = vecorized_buy_sell(pred, X_test)\n",
    "signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1fcb451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 07:22:51.605555: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#Basic \n",
    "import numpy as np\n",
    "#LSTM Functions\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import LSTM \n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650c3e8",
   "metadata": {},
   "source": [
    "## Seperate: The LSTM Predictions\n",
    "Future Items: \n",
    "    Customize the future_days available.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d8cec",
   "metadata": {},
   "source": [
    "Overhead for the data: Consider this an independant function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3ade78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_finalize(df ):\n",
    "#   PRE: Recieves a data frame from the Alpaca_connection.get_data_today package.  Pandas is already installed.  \n",
    "#   POST: Finalizes a data frame that is ready for next steps. \n",
    "#   Intent: Band-aid for data handling.  Consider closing the gap in get_data_today\n",
    "#   Improvements: Replace function ALL together\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns = {'open':'Open', 'high':'High', 'low':'Low', 'close':'Close', 'volume':'Volume', 'trade_count':'Trade Count'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d5172",
   "metadata": {},
   "source": [
    "Below we should encapsulate this into a single function that can prep for LTSM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a55c084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_prep(df, future_days = 38):\n",
    "#.  PRE: Pandas is already installed and we recieve a data frame\n",
    "#.  POST: We have split data frames that is ready for train/testing.  \n",
    "#.  Intent: Take the incoming data frame and break it out to train/test\n",
    "#.  Improvement: Convert the output to df.  \n",
    "\n",
    "#.  THis is the target preictor: Conside\n",
    "    df['Prediction'] = df[['Close']].shift(-future_days)\n",
    "    \n",
    "#.  We identify the predictor/response.  \n",
    "    X = np.array(df.drop(['Prediction','index', 'symbol', 'timestamp'], axis = 1))[:-future_days]\n",
    "    y = np.array(df['Prediction'])[:-future_days]\n",
    "\n",
    "\n",
    "    # Finally, we use the prediction column to create an array of the the future predictor days.  \n",
    "    # Get the last 'x' rows of the feature data set\n",
    "    x_future = df.drop(['index','Prediction', 'symbol', 'timestamp'],axis = 1)[:-future_days]\n",
    "    x_future = x_future.tail(future_days)\n",
    "    x_future = np.array(x_future)\n",
    "    # ## Splitting the data for performance testing\n",
    "    # In addition to the visual analysis, we are going to want to use our conventional Test/train split in order to train the data. We can use our conventional train_test_split dividing our 'live' close date with our prediction close date.   \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe96a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Builds the actual LTSM Network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92bb55ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(df, future_days = 38):\n",
    "#.   PRE: We recieve a data frame that is fit for LSTM training.  \n",
    "#.   Post: We return our predicted values.  \n",
    "#.   Intent: TO be able to generate the prdeictions from the lSTM \n",
    "#.   Improvements: Return the test results: In case we get a low accuracy.  More parameters for fiddlingwith the layers and hyperparameters.  \n",
    "\n",
    "    # As seen before we are going to look at the market close data and prepare all but 38 values to generate predictions.  \n",
    "    lstmData = df.filter(['Close'])\n",
    "    dataset = lstmData.values\n",
    "    training_data_len = len(dataset)-future_days\n",
    "\n",
    "\n",
    "    # Now as mentioned above, we have to scale the data.  Using the min max scaler we can turn all of our data into decimals (except for the min =0 and max =1).  We will save this data into our scaled_data datset.    \n",
    "    #Scale the data \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "\n",
    "    # Below you will see that we need to split the data again into x and y train and test.  Using a 60 day offset we can append them to an empty list using the prior 60 days to predict the next 60 days.  \n",
    "    #Re create Training Set \n",
    "    lstm_train_data = scaled_data[0:training_data_len,:]\n",
    "    test_data = scaled_data[training_data_len - 60: ,:]\n",
    "\n",
    "    # Create the datasets\n",
    "    lstm_x_train = []\n",
    "    lstm_y_train = []\n",
    "    lstm_x_test = []\n",
    "    lstm_y_test = dataset[training_data_len:, :]\n",
    "\n",
    "    for i in range(60, len(lstm_train_data)):\n",
    "        lstm_x_train.append(lstm_train_data[i-60:i])\n",
    "        lstm_y_train.append(lstm_train_data[i,0])\n",
    "    \n",
    "\n",
    "    for i in range(60, len(test_data)): \n",
    "        lstm_x_test.append(test_data[i-60:i, 0])    \n",
    "\n",
    "\n",
    "    # Now we have to convert the lists into numpy arrays so the data can be read.  Also, we have to reshape them into a format that the LSTM will understand.  \n",
    "\n",
    "    #Conver to numpy\n",
    "    lstm_x_train, lstm_y_train =   np.array(lstm_x_train), np.array(lstm_y_train)\n",
    "    lstm_x_test = np.array(lstm_x_test)\n",
    "    #Reshape the data\n",
    "    lstm_x_train = np.reshape(lstm_x_train, (lstm_x_train.shape[0], lstm_x_train.shape[1], 1))\n",
    "    lstm_x_test = np.reshape(lstm_x_test, (lstm_x_test.shape[0], lstm_x_test.shape[1], 1))\n",
    "\n",
    "\n",
    "    # Finally, we are back to building the models.  We are using 4 layers: The first two training layers then a dense layer and finally an output layer.  \n",
    "    model = Sequential() \n",
    "    model.add(LSTM(50, return_sequences = True, input_shape=(lstm_x_train.shape[1],1)))\n",
    "    model.add(LSTM(50, return_sequences = False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    # Now that we have created the network, we can run the data through using the MSE method.  We will use 10 epocs because the loss is low, but futher iterations are not necessary.  Finally we have to undo the scaling to our predictions.  \n",
    "\n",
    "    #Compile the model \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    #Train the model \n",
    "    model.fit(lstm_x_train, lstm_y_train, batch_size = 1, epochs = 10)  \n",
    "    LSTM_predictions = model.predict(lstm_x_test)\n",
    "    LSTM_predictions = scaler.inverse_transform(LSTM_predictions)\n",
    "    LSTM_predictions\n",
    "\n",
    "\n",
    "    # Because of the necessary transformations that were done to the model, we cannot use the same function as above. However we can poach  a massive chunk from above and paste it into our model.  \n",
    "\n",
    "    t = lstmData[:training_data_len]\n",
    "    v = lstmData[training_data_len:]\n",
    "    v['Predictions'] = LSTM_predictions\n",
    "\n",
    "\n",
    "\n",
    "#    print(mean_squared_error(X_test[:38],LSTM_predictions))\n",
    "#    print(\"Actual Values:\")\n",
    "#    print([row[2] for row in X_test])\n",
    "    return  LSTM_predictions# [row[2] for row in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we have the actual buy sell strategy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f87edac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecorized_buy_sell(ls_pred, arr_actuals):\n",
    "    import pandas as pd\n",
    "    buy_sell = pd.DataFrame({\"Actuals\": [row[2] for row in arr_actuals][:]})#, \"Predictions\":LSTM_predictions })\n",
    "    buy_sell[\"Predictions\"] = ls_pred\n",
    "    buy_sell[\"Predictions Offset\"] = pd.DataFrame(ls_pred).shift(1)\n",
    "    buy_sell[\"signal\"] = np.where(buy_sell[\"Actuals\"]> buy_sell[\"Predictions Offset\"], 1, -1 )\n",
    "    buy_sell[\"returns\"] = np.log(buy_sell[\"Actuals\"]/ buy_sell[\"Actuals\"].shift(1))\n",
    "    buy_sell[\"strategy\"] = buy_sell[\"returns\"]*buy_sell[\"signal\"]\n",
    "    return buy_sell\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15ae84d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row[2] for row in X_test][51:]#[len(pred):]\n",
    "len([row[2] for row in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0fb69a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_backtest(ls, cycles = 32): \n",
    "#.   Pre: Takes a list of stock market predictions.\n",
    "#.   Post: We use these predictions to buy/sell through the entire cycle. \n",
    "#.   Intent: Basic backtest to view strategy moving forward. \n",
    "#.   FIX THE HARDCODE.  Improvement: Allow for downstream charting. \n",
    "    import pandas as pd\n",
    "    buy_sell = pd.DataFrame({\"Actuals\": [row[2] for row in X_test][53:]})#, \"Predictions\":LSTM_predictions })\n",
    "    buy_sell[\"Predictions\"] = pred\n",
    "    buy_sell[\"Predictions Offset\"] = pd.DataFrame(LSTM_predictions).shift(1)\n",
    "    buy_sell[\"signal\"] = np.where(buy_sell[\"Actuals\"]> buy_sell[\"Predictions Offset\"], 1, -1 )\n",
    "    buy_sell[\"returns\"] = np.log(buy_sell[\"Actuals\"]/ buy_sell[\"Actuals\"].shift(1))\n",
    "    buy_sell[\"strategy\"] = buy_sell[\"returns\"]*buy_sell[\"signal\"]\n",
    "    #buy_sell\n",
    "    \n",
    "    buy_sell[[\"returns\", \"strategy\"]].sum()\n",
    "    buy_sell[[\"returns\", \"strategy\"]].sum().apply(np.exp)\n",
    "    buy_sell[[\"returns\", \"strategy\"]].cumsum().apply(np.exp).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "870b178a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actuals</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Predictions Offset</th>\n",
       "      <th>signal</th>\n",
       "      <th>returns</th>\n",
       "      <th>strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151.0000</td>\n",
       "      <td>151.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.9800</td>\n",
       "      <td>128.9800</td>\n",
       "      <td>151.0000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.157622</td>\n",
       "      <td>0.157622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140.7800</td>\n",
       "      <td>140.7800</td>\n",
       "      <td>128.9800</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.087541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147.3100</td>\n",
       "      <td>147.3100</td>\n",
       "      <td>140.7800</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045341</td>\n",
       "      <td>0.045341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135.2300</td>\n",
       "      <td>135.2300</td>\n",
       "      <td>147.3100</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.085562</td>\n",
       "      <td>0.085562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>136.3500</td>\n",
       "      <td>136.3500</td>\n",
       "      <td>135.2300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.008248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147.7400</td>\n",
       "      <td>147.7400</td>\n",
       "      <td>136.3500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080229</td>\n",
       "      <td>0.080229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>127.4200</td>\n",
       "      <td>127.4200</td>\n",
       "      <td>147.7400</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.147965</td>\n",
       "      <td>0.147965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>130.0800</td>\n",
       "      <td>130.0800</td>\n",
       "      <td>127.4200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.020661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>136.4400</td>\n",
       "      <td>136.4400</td>\n",
       "      <td>130.0800</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047735</td>\n",
       "      <td>0.047735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>149.7901</td>\n",
       "      <td>149.7901</td>\n",
       "      <td>136.4400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093350</td>\n",
       "      <td>0.093350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>130.8200</td>\n",
       "      <td>130.8200</td>\n",
       "      <td>149.7901</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.135413</td>\n",
       "      <td>0.135413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>144.4900</td>\n",
       "      <td>144.4900</td>\n",
       "      <td>130.8200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099388</td>\n",
       "      <td>0.099388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>150.1700</td>\n",
       "      <td>150.1700</td>\n",
       "      <td>144.4900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038558</td>\n",
       "      <td>0.038558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>145.3644</td>\n",
       "      <td>145.3644</td>\n",
       "      <td>150.1700</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.032524</td>\n",
       "      <td>0.032524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>127.6000</td>\n",
       "      <td>127.6000</td>\n",
       "      <td>145.3644</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.130343</td>\n",
       "      <td>0.130343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>146.9600</td>\n",
       "      <td>146.9600</td>\n",
       "      <td>127.6000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.141260</td>\n",
       "      <td>0.141260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>132.3100</td>\n",
       "      <td>132.3100</td>\n",
       "      <td>146.9600</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.105013</td>\n",
       "      <td>0.105013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>134.9000</td>\n",
       "      <td>134.9000</td>\n",
       "      <td>132.3100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019386</td>\n",
       "      <td>0.019386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>144.3300</td>\n",
       "      <td>144.3300</td>\n",
       "      <td>134.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067569</td>\n",
       "      <td>0.067569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>133.8300</td>\n",
       "      <td>133.8300</td>\n",
       "      <td>144.3300</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.075532</td>\n",
       "      <td>0.075532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>155.9600</td>\n",
       "      <td>155.9600</td>\n",
       "      <td>133.8300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153029</td>\n",
       "      <td>0.153029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>133.3022</td>\n",
       "      <td>133.3022</td>\n",
       "      <td>155.9600</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.156981</td>\n",
       "      <td>0.156981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>144.4200</td>\n",
       "      <td>144.4200</td>\n",
       "      <td>133.3022</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080107</td>\n",
       "      <td>0.080107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>137.6304</td>\n",
       "      <td>137.6304</td>\n",
       "      <td>144.4200</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.048154</td>\n",
       "      <td>0.048154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>147.6000</td>\n",
       "      <td>147.6000</td>\n",
       "      <td>137.6304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069934</td>\n",
       "      <td>0.069934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>144.8900</td>\n",
       "      <td>144.8900</td>\n",
       "      <td>147.6000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.018531</td>\n",
       "      <td>0.018531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>134.8500</td>\n",
       "      <td>134.8500</td>\n",
       "      <td>144.8900</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.071812</td>\n",
       "      <td>0.071812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>128.0000</td>\n",
       "      <td>128.0000</td>\n",
       "      <td>134.8500</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.052133</td>\n",
       "      <td>0.052133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>121.9771</td>\n",
       "      <td>121.9771</td>\n",
       "      <td>128.0000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.048197</td>\n",
       "      <td>0.048197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>135.0000</td>\n",
       "      <td>135.0000</td>\n",
       "      <td>121.9771</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101441</td>\n",
       "      <td>0.101441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>139.5000</td>\n",
       "      <td>139.5000</td>\n",
       "      <td>135.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>0.032790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>125.3700</td>\n",
       "      <td>125.3700</td>\n",
       "      <td>139.5000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.106795</td>\n",
       "      <td>0.106795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>147.6750</td>\n",
       "      <td>147.6750</td>\n",
       "      <td>125.3700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163745</td>\n",
       "      <td>0.163745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>130.8200</td>\n",
       "      <td>130.8200</td>\n",
       "      <td>147.6750</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.121192</td>\n",
       "      <td>0.121192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>130.3600</td>\n",
       "      <td>130.3600</td>\n",
       "      <td>130.8200</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.003522</td>\n",
       "      <td>0.003522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>130.0100</td>\n",
       "      <td>130.0100</td>\n",
       "      <td>130.3600</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.002688</td>\n",
       "      <td>0.002688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>133.2002</td>\n",
       "      <td>133.2002</td>\n",
       "      <td>130.0100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>0.024242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>135.3700</td>\n",
       "      <td>135.3700</td>\n",
       "      <td>133.2002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016159</td>\n",
       "      <td>0.016159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>152.1300</td>\n",
       "      <td>152.1300</td>\n",
       "      <td>135.3700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116724</td>\n",
       "      <td>0.116724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>149.5400</td>\n",
       "      <td>149.5400</td>\n",
       "      <td>152.1300</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.017172</td>\n",
       "      <td>0.017172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>131.6608</td>\n",
       "      <td>131.6608</td>\n",
       "      <td>149.5400</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.127335</td>\n",
       "      <td>0.127335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>132.3600</td>\n",
       "      <td>132.3600</td>\n",
       "      <td>131.6608</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>139.2050</td>\n",
       "      <td>139.2050</td>\n",
       "      <td>132.3600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050422</td>\n",
       "      <td>0.050422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>152.0550</td>\n",
       "      <td>152.0550</td>\n",
       "      <td>139.2050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088295</td>\n",
       "      <td>0.088295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>146.7100</td>\n",
       "      <td>146.7100</td>\n",
       "      <td>152.0550</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.035784</td>\n",
       "      <td>0.035784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>156.0300</td>\n",
       "      <td>156.0300</td>\n",
       "      <td>146.7100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061590</td>\n",
       "      <td>0.061590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>139.2942</td>\n",
       "      <td>139.2942</td>\n",
       "      <td>156.0300</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.113460</td>\n",
       "      <td>0.113460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>148.1800</td>\n",
       "      <td>148.1800</td>\n",
       "      <td>139.2942</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061840</td>\n",
       "      <td>0.061840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>134.6900</td>\n",
       "      <td>134.6900</td>\n",
       "      <td>148.1800</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.095452</td>\n",
       "      <td>0.095452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>128.9101</td>\n",
       "      <td>128.9101</td>\n",
       "      <td>134.6900</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.043861</td>\n",
       "      <td>0.043861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>151.0900</td>\n",
       "      <td>151.0900</td>\n",
       "      <td>128.9101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158760</td>\n",
       "      <td>0.158760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>150.6400</td>\n",
       "      <td>150.6400</td>\n",
       "      <td>151.0900</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actuals  Predictions  Predictions Offset  signal   returns  strategy\n",
       "0   151.0000     151.0000                 NaN      -1       NaN       NaN\n",
       "1   128.9800     128.9800            151.0000      -1 -0.157622  0.157622\n",
       "2   140.7800     140.7800            128.9800       1  0.087541  0.087541\n",
       "3   147.3100     147.3100            140.7800       1  0.045341  0.045341\n",
       "4   135.2300     135.2300            147.3100      -1 -0.085562  0.085562\n",
       "5   136.3500     136.3500            135.2300       1  0.008248  0.008248\n",
       "6   147.7400     147.7400            136.3500       1  0.080229  0.080229\n",
       "7   127.4200     127.4200            147.7400      -1 -0.147965  0.147965\n",
       "8   130.0800     130.0800            127.4200       1  0.020661  0.020661\n",
       "9   136.4400     136.4400            130.0800       1  0.047735  0.047735\n",
       "10  149.7901     149.7901            136.4400       1  0.093350  0.093350\n",
       "11  130.8200     130.8200            149.7901      -1 -0.135413  0.135413\n",
       "12  144.4900     144.4900            130.8200       1  0.099388  0.099388\n",
       "13  150.1700     150.1700            144.4900       1  0.038558  0.038558\n",
       "14  145.3644     145.3644            150.1700      -1 -0.032524  0.032524\n",
       "15  127.6000     127.6000            145.3644      -1 -0.130343  0.130343\n",
       "16  146.9600     146.9600            127.6000       1  0.141260  0.141260\n",
       "17  132.3100     132.3100            146.9600      -1 -0.105013  0.105013\n",
       "18  134.9000     134.9000            132.3100       1  0.019386  0.019386\n",
       "19  144.3300     144.3300            134.9000       1  0.067569  0.067569\n",
       "20  133.8300     133.8300            144.3300      -1 -0.075532  0.075532\n",
       "21  155.9600     155.9600            133.8300       1  0.153029  0.153029\n",
       "22  133.3022     133.3022            155.9600      -1 -0.156981  0.156981\n",
       "23  144.4200     144.4200            133.3022       1  0.080107  0.080107\n",
       "24  137.6304     137.6304            144.4200      -1 -0.048154  0.048154\n",
       "25  147.6000     147.6000            137.6304       1  0.069934  0.069934\n",
       "26  144.8900     144.8900            147.6000      -1 -0.018531  0.018531\n",
       "27  134.8500     134.8500            144.8900      -1 -0.071812  0.071812\n",
       "28  128.0000     128.0000            134.8500      -1 -0.052133  0.052133\n",
       "29  121.9771     121.9771            128.0000      -1 -0.048197  0.048197\n",
       "30  135.0000     135.0000            121.9771       1  0.101441  0.101441\n",
       "31  139.5000     139.5000            135.0000       1  0.032790  0.032790\n",
       "32  125.3700     125.3700            139.5000      -1 -0.106795  0.106795\n",
       "33  147.6750     147.6750            125.3700       1  0.163745  0.163745\n",
       "34  130.8200     130.8200            147.6750      -1 -0.121192  0.121192\n",
       "35  130.3600     130.3600            130.8200      -1 -0.003522  0.003522\n",
       "36  130.0100     130.0100            130.3600      -1 -0.002688  0.002688\n",
       "37  133.2002     133.2002            130.0100       1  0.024242  0.024242\n",
       "38  135.3700     135.3700            133.2002       1  0.016159  0.016159\n",
       "39  152.1300     152.1300            135.3700       1  0.116724  0.116724\n",
       "40  149.5400     149.5400            152.1300      -1 -0.017172  0.017172\n",
       "41  131.6608     131.6608            149.5400      -1 -0.127335  0.127335\n",
       "42  132.3600     132.3600            131.6608       1  0.005297  0.005297\n",
       "43  139.2050     139.2050            132.3600       1  0.050422  0.050422\n",
       "44  152.0550     152.0550            139.2050       1  0.088295  0.088295\n",
       "45  146.7100     146.7100            152.0550      -1 -0.035784  0.035784\n",
       "46  156.0300     156.0300            146.7100       1  0.061590  0.061590\n",
       "47  139.2942     139.2942            156.0300      -1 -0.113460  0.113460\n",
       "48  148.1800     148.1800            139.2942       1  0.061840  0.061840\n",
       "49  134.6900     134.6900            148.1800      -1 -0.095452  0.095452\n",
       "50  128.9101     128.9101            134.6900      -1 -0.043861  0.043861\n",
       "51  151.0900     151.0900            128.9101       1  0.158760  0.158760\n",
       "52  150.6400     150.6400            151.0900      -1 -0.002983  0.002983"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = vecorized_buy_sell(pred, X_test)\n",
    "#signal = vectorized_backtest(pred)\n",
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_test[0][2]\n",
    "#df.head()\n",
    "#X_test[0]\n",
    "\n",
    "    \n",
    "[row[2] for row in X_test]\n",
    "\n",
    "\n",
    "# ## Buy/Sell Strategy: \n",
    "# If the next prediction is less than current actual: Sell\n",
    "# If the next prediction is more than the current actual: Buy\n",
    "# Create a dataframe of the values with the buy/sell signal.  \n",
    "# Then create look into backtesting the signal.  \n",
    "\n",
    "\n",
    "def vectorized_backtest(ls, cycles = 32): \n",
    "#.   Pre: Takes a list of stock market predictions.\n",
    "#.   Post: We use these predictions to buy/sell through the entire cycle. \n",
    "#.   Intent: Basic backtest to view strategy moving forward. \n",
    "#.   Improvement: Allow for downstream charting\n",
    "    import pandas as pd\n",
    "    buy_sell = pd.DataFrame({\"Actuals\": [row[2] for row in X_test][15:]})#, \"Predictions\":LSTM_predictions })\n",
    "    buy_sell[\"Predictions\"] = LSTM_predictions\n",
    "    buy_sell[\"Predictions Offset\"] = pd.DataFrame(LSTM_predictions).shift(1)\n",
    "    buy_sell[\"signal\"] = np.where(buy_sell[\"Actuals\"]> buy_sell[\"Predictions Offset\"], 1, -1 )\n",
    "    buy_sell[\"returns\"] = np.log(buy_sell[\"Actuals\"]/ buy_sell[\"Actuals\"].shift(1))\n",
    "    buy_sell[\"strategy\"] = buy_sell[\"returns\"]*buy_sell[\"signal\"]\n",
    "    #buy_sell\n",
    "    \n",
    "    buy_sell[[\"returns\", \"strategy\"]].sum()\n",
    "    buy_sell[[\"returns\", \"strategy\"]].sum().apply(np.exp)\n",
    "    buy_sell[[\"returns\", \"strategy\"]].cumsum().apply(np.exp).plot()\n",
    "\n",
    "\n",
    "# ## Average period return risk statistics for both the stock and strategy. \n",
    "# (32 = # of cycles; 252 = annual period)\n",
    "# \n",
    "# Calculates the period mean return in both log and regular price\n",
    "#  \n",
    "# Conclusion(8/30): Equal risk, much higher reward\n",
    "    buy_sell[['returns', 'strategy']].mean()*cycles\n",
    "    np.exp(buy_sell[['returns', 'strategy']].mean()*cycles)-1\n",
    "buy_sell[['returns', 'strategy']].std()*cycles**.5\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "(buy_sell[['returns', 'strategy']].apply(np.exp)-1).std()*32**.5\n",
    "\n",
    "\n",
    "# ## Evaluate the drawdaown with the cummax/cumret\n",
    "# \n",
    "# Defines a new column, cumret, with a gross performance over time\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "## Evaluate the drawdaown with the cummax/cumret \n",
    "buy_sell['cumret'] =buy_sell['strategy'].cumsum().apply(np.exp)\n",
    "\n",
    "\n",
    "# Defines yet another column with a running maximum value of the gross performance\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "buy_sell['cummax'] = buy_sell['cumret'].cummax()\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "buy_sell[['cumret', 'cummax']].dropna().plot(figsize= (10,6))\n",
    "\n",
    "\n",
    "# The max drawdown is calcualated as the difference between the two columns\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "drawdown = buy_sell['cummax'] - buy_sell['cumret']\n",
    "drawdown.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fea917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PRE: Accepts a pandas data frame with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205949f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
